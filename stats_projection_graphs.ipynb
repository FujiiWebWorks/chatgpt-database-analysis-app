{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3Wbr7fsIlAcS"
      },
      "source": [
        "# projection_graphsテーブル統計データ\n",
        "\n",
        "projection_graphsテーブル(structures間の投射関係を表す重み付き有向グラフ)の統計データです。\n",
        "\n",
        "※調整中（データ量が多すぎるため表示できない）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pythonライブラリインストール\n",
        "!python --version\n",
        "!pip install python-dotenv\n",
        "\n",
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install plotly\n",
        "!pip install -U kaleido\n",
        "!pip install -U nbformat\n",
        "!pip install scikit-learn\n",
        "!pip install sqlalchemy\n",
        "!pip install \"dask[complete]\"\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 環境変数\n",
        "supabase接続用URL,APIキーと、openai api接続用のAPIキーを設定します。\n",
        "自身のopenaiアカウントからapi keyを取得してください。\n",
        "\n",
        "https://platform.openai.com/account/api-keys\n",
        "\n",
        "supabaseの情報は管理者にお尋ねください。\n",
        "\n",
        "下記の例では、.envファイルに変数を書き込んで、JupiterNotebookで読み込む仕様で実装しております。\n",
        "\n",
        "※.envファイルの作成が困難、.envファイルから値を読み込めない場合、\n",
        "　os.getenv(\"◯◯\")部分に変数値を直接書き込んでいただいても動作自体には問題ありません。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "4XTDUNmukjRT",
        "outputId": "263e8bb3-d37d-464e-e9db-28693cb5bfc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "環境変数読み込み完了\n"
          ]
        }
      ],
      "source": [
        "# 環境変数\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "from sqlalchemy import create_engine\n",
        "from sqlalchemy import text\n",
        "import urllib.parse\n",
        "\n",
        "import dask.dataframe as dd\n",
        "from dask.distributed import Client\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# supabase接続用変数\n",
        "db_host = os.getenv(\"DB_HOST\")\n",
        "db_port = os.getenv(\"DB_PORT\")\n",
        "db_name = os.getenv(\"DB_NAME\")\n",
        "db_user = os.getenv(\"DB_USER\")\n",
        "db_pass = os.getenv(\"DB_PASS\")\n",
        "\n",
        "# Connect to the database\n",
        "connection_config = {\n",
        "    'user': db_user,\n",
        "    'password': urllib.parse.quote_plus(db_pass),\n",
        "    'host': db_host,\n",
        "    'port': db_port, \n",
        "    'database': db_name\n",
        "}\n",
        "engine = create_engine('postgresql://{user}:{password}@{host}:{port}/{database}'.format(**connection_config))\n",
        "sql = 'SELECT * FROM projection_graphs ORDER BY \"injected-structure-id\" ASC;'\n",
        "\n",
        "with engine.begin() as conn:\n",
        "    query = text(sql)\n",
        "    df_original = pd.read_sql_query(query, conn)\n",
        "\n",
        "print('環境変数読み込み完了')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 処理関数\n",
        "\n",
        "- ヒストグラム\n",
        "- 円グラフ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkBzMSLwewf6",
        "outputId": "3b84bb5b-29c8-47ee-87e7-52a5394c9efe"
      },
      "outputs": [],
      "source": [
        "\n",
        "%matplotlib inline\n",
        "\n",
        "def piechart(label:str, df, title:str):\n",
        "  # Counting the occurrences of each category\n",
        "  category_counts = df[label].value_counts()\n",
        "  # Plotting the pie chart\n",
        "  plt.pie(category_counts, labels=category_counts.index, autopct='%1.1f%%',startangle=90)\n",
        "  plt.title(title+'(n='+str(len(df))+')')\n",
        "  plt.axis('equal')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def histgram(label:str, df, xlabel:str, ylabel:str, title:str, x_max):\n",
        "  # If you want to use multiple cores, set the number of workers and threads per worker\n",
        "  client = Client(n_workers=4, threads_per_worker=1)\n",
        "  client\n",
        "\n",
        "  data = df[label]\n",
        "\n",
        "  # Compute basic statistics for the selected column\n",
        "  min_value, max_value = data.min().compute(), data.max().compute()\n",
        "\n",
        "  # Determine the number of bins and range for the histogram\n",
        "  hist_range = (min_value, max_value)\n",
        "\n",
        "  # Create a Pandas histogram from the Dask DataFrame\n",
        "  hist, bin_edges = np.histogram(data, bins=len(set(df[label])), range=hist_range)\n",
        "\n",
        "  # Plot the histogram using matplotlib\n",
        "  plt.hist(bin_edges[:-1], bin_edges, weights=hist)\n",
        "  plt.xlabel(xlabel)\n",
        "  plt.ylabel(ylabel)\n",
        "  plt.title(title)\n",
        "\n",
        "\n",
        "  mean = np.mean(df[label])\n",
        "  median = np.median(df[label])\n",
        "  std_dev = np.std(df[label])\n",
        "\n",
        "  y_max = max(n)\n",
        "  # Add statistics to the plot\n",
        "  plt.axvline(mean, color='red', linestyle='dashed', linewidth=2)\n",
        "  plt.text(mean+1, (plt.ylim()[1]-y_max/4), f'Mean: {mean}', color='red')\n",
        "\n",
        "  plt.axvline(median, color='blue', linestyle='solid', linewidth=2)\n",
        "  plt.text(median+1, (plt.ylim()[1]-y_max/3), f'Median: {median}', color='blue')\n",
        "\n",
        "  plt.axhline(std_dev, color='green', linestyle='dotted', linewidth=2)\n",
        "  plt.text(plt.xlim()[0], std_dev, f'Std Dev: {std_dev:.2f}', color='green')\n",
        "\n",
        "  # Show the plot\n",
        "  if x_max is None:\n",
        "    x_max = max(df[label])\n",
        "  plt.xlim(min(df[label]),x_max)\n",
        "\n",
        "  plt.show()\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 処理結果"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read your large dataset (assuming it's a .csv file) in chunks using Dask DataFrame\n",
        "df = dd.from_pandas(df_original, chunksize=1000)\n",
        "\n",
        "histgram('normalized-projection-volume', df, 'normalized-projection-volume', '', 'normalized-projection-volume', None)\n",
        "histgram('projection-density', df, 'projection-density', '', 'projection-density', None)\n",
        "histgram('projection-energy', df, 'projection-energy', '', 'projection-energy', None)\n",
        "histgram('projection-intensity', df, 'projection-intensity', '', 'projection-intensity', None)\n",
        "histgram('projection-volume', df, 'projection-volume', '', 'projection-volume', None)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
