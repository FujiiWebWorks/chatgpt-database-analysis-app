{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3Wbr7fsIlAcS"
      },
      "source": [
        "# 各脳部位間の投射関係の重み付き有向グラフ化（projection_graphs）\n",
        "\n",
        "projections, specimensテーブルを元に、脳部位Aから脳部位Bへの投射関係を示すデータ列を作成する。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pythonライブラリインストール\n",
        "!python --version\n",
        "!pip install psycopg2-binary\n",
        "!pip install python-dotenv\n",
        "\n",
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install plotly\n",
        "!pip install scikit-learn\n",
        "!pip install sqlalchemy\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 環境変数\n",
        "supabase接続用URL,APIキーと、openai api接続用のAPIキーを設定します。\n",
        "自身のopenaiアカウントからapi keyを取得してください。\n",
        "\n",
        "https://platform.openai.com/account/api-keys\n",
        "\n",
        "supabaseの情報は管理者にお尋ねください。\n",
        "\n",
        "下記の例では、.envファイルに変数を書き込んで、JupiterNotebookで読み込む仕様で実装しております。\n",
        "\n",
        "※.envファイルの作成が困難、.envファイルから値を読み込めない場合、\n",
        "　os.getenv(\"◯◯\")部分に変数値を直接書き込んでいただいても動作自体には問題ありません。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "4XTDUNmukjRT",
        "outputId": "263e8bb3-d37d-464e-e9db-28693cb5bfc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "環境変数読み込み完了\n"
          ]
        }
      ],
      "source": [
        "# 環境変数\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "from sqlalchemy import text\n",
        "import urllib.parse\n",
        "from IPython.display import display\n",
        "\n",
        "# supabase接続用変数\n",
        "db_host = os.getenv(\"DB_HOST\")\n",
        "db_port = os.getenv(\"DB_PORT\")\n",
        "db_name = os.getenv(\"DB_NAME\")\n",
        "db_user = os.getenv(\"DB_USER\")\n",
        "db_pass = os.getenv(\"DB_PASS\")\n",
        "\n",
        "# Connect to the database\n",
        "connection_config = {\n",
        "    'user': db_user,\n",
        "    'password': urllib.parse.quote_plus(db_pass),\n",
        "    'host': db_host,\n",
        "    'port': db_port, \n",
        "    'database': db_name\n",
        "}\n",
        "engine = create_engine('postgresql://{user}:{password}@{host}:{port}/{database}'.format(**connection_config))\n",
        "\n",
        "print('環境変数読み込み完了')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 処理実行\n",
        "\n",
        "structures全ての要素iに対して下記を実行\n",
        "\n",
        "1. 要素iが注入部位となった実験結果を抽出\n",
        "2. \"normalized-projection-volume\",　\"projection-density\",　\"projection-energy\",　\"projection-intensity\",　\"projection-volume\"の平均値を計算\n",
        "3. projection_graphsテーブルに保存"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkBzMSLwewf6",
        "outputId": "3b84bb5b-29c8-47ee-87e7-52a5394c9efe"
      },
      "outputs": [],
      "source": [
        "threshold_level = 4\n",
        "\n",
        "# structuresを全て書き出し\n",
        "sql =\"\"\"\n",
        "SELECT\n",
        "    id,\n",
        "    name,\n",
        "    acronym,\n",
        "    \"st-level\",\n",
        "    \"parent-structure-id\"\n",
        "FROM\n",
        "    structures\n",
        "ORDER BY\n",
        "    \"st-level\" ASC;\"\"\"\n",
        "with engine.begin() as conn:\n",
        "    query = text(sql)\n",
        "    df_structures = pd.read_sql_query(query, conn)\n",
        "\n",
        "# 子要素を持たない要素\n",
        "terminal_structure_ids = df_structures.loc[~df_structures['id'].isin(df_structures['parent-structure-id'])]['id']\n",
        "\n",
        "\n",
        "def get_children(parent_id):\n",
        "    return df_structures[df_structures[\"parent-structure-id\"] == parent_id]\n",
        "\n",
        "def build_hierarchy(parent_id, level=0):\n",
        "    children = get_children(parent_id)\n",
        "    hierarchy = {}\n",
        "    for _, child in children.iterrows():\n",
        "        child_id = child[\"id\"]\n",
        "        hierarchy[child_id] = {\"level\": level, \"acronym\": child['acronym'], \"children\": build_hierarchy(child_id, level + 1)}\n",
        "        structure_ids.append(child_id)\n",
        "    return hierarchy\n",
        "\n",
        "df_small_structures = df_structures[df_structures['st-level'] > threshold_level]\n",
        "\n",
        "# Iterate through each row in the DataFrame\n",
        "for index, row in df_small_structures.iterrows():\n",
        "    if(index<486):\n",
        "        continue\n",
        "    print(f'Index: {index}/{len(df_small_structures)}, Name: {row[\"name\"]}, Acronym: {row[\"acronym\"]}, st-level: {row[\"st-level\"]}')\n",
        "\n",
        "    structure_ids = [row[\"id\"]]\n",
        "    hierarchy = build_hierarchy(row[\"id\"])\n",
        "\n",
        "    print(structure_ids)\n",
        "\n",
        "    # 投射情報\n",
        "    sql =f\"\"\"\n",
        "    SELECT\n",
        "        p.id,\n",
        "        p.\"structure-id\" AS \"projected-structure-id\",\n",
        "        s.name,\n",
        "        s.acronym,\n",
        "        p.\"normalized-projection-volume\",\n",
        "        p.\"projection-density\",\n",
        "        p.\"projection-energy\",\n",
        "        p.\"projection-intensity\",\n",
        "        p.\"projection-volume\",\n",
        "        sp.\"structure-id\"\n",
        "    FROM projections AS p\n",
        "        INNER JOIN specimens AS sp ON p.\"experiment-id\" = sp.\"experiment-id\"\n",
        "        INNER JOIN structures AS s ON p.\"structure-id\" = s.id\n",
        "    WHERE\n",
        "        sp.\"structure-id\" IN :structure_ids\n",
        "        AND p.\"is-injection\" = false\n",
        "        AND s.\"st-level\" > {threshold_level};\n",
        "    \"\"\"\n",
        "    with engine.begin() as conn:\n",
        "        query = text(sql)\n",
        "        df_projections = pd.read_sql_query(query, conn, params={\"structure_ids\": tuple(structure_ids)})\n",
        "\n",
        "        #display(df_projections)\n",
        "\n",
        "    if(len(df_projections)>0):\n",
        "        df = pd.DataFrame()\n",
        "        average_normalized_volume_df = df_projections.groupby('projected-structure-id')['normalized-projection-volume'].mean().to_frame('normalized-projection-volume')\n",
        "        average_density_df = df_projections.groupby('projected-structure-id')['projection-density'].mean().to_frame('projection-density')\n",
        "        average_energy_df = df_projections.groupby('projected-structure-id')['projection-energy'].mean().to_frame('projection-energy')\n",
        "        average_intensity_df = df_projections.groupby('projected-structure-id')['projection-intensity'].mean().to_frame('projection-intensity')\n",
        "        average_volume_df = df_projections.groupby('projected-structure-id')['projection-volume'].mean().to_frame('projection-volume')\n",
        "\n",
        "        # Concatenate the three DataFrames\n",
        "        df = pd.concat([average_normalized_volume_df, average_density_df, average_energy_df, average_intensity_df, average_volume_df], axis=1)\n",
        "\n",
        "        # Set the float_format option to display floats with a fixed number of decimal places\n",
        "        pd.set_option('display.float_format', '{:.10f}'.format)\n",
        "\n",
        "        #display(df)\n",
        "        \n",
        "        df['injected-structure-id'] = row[\"id\"]\n",
        "        df['projected-structure-id'] = df.index\n",
        "        df=df.reset_index(drop=True)\n",
        "\n",
        "        df['graph-id'] = df['injected-structure-id'].astype(str) + \"->\" + df['projected-structure-id'].astype(str)\n",
        "\n",
        "        display(df)\n",
        "\n",
        "        # Save the concatenated DataFrame to SQL table\n",
        "        #df.to_sql('projection_graphs', con=engine, if_exists='replace', index=False) \n",
        "        \n",
        "        # Assuming df is your DataFrame\n",
        "        chunk_size = 2000  # Adjust this value according to your needs\n",
        "        # Calculate the number of chunks\n",
        "        num_chunks = (len(df) // chunk_size) + 1\n",
        "\n",
        "        # Iterate over each chunk and write to the database\n",
        "        for i in range(num_chunks):\n",
        "            start_idx = i * chunk_size\n",
        "            end_idx = (i + 1) * chunk_size\n",
        "            df_chunk = df.iloc[start_idx:end_idx]\n",
        "            try:\n",
        "                df_chunk.to_sql('projection_graphs', con=engine, if_exists='append', index=False)\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred while writing the DataFrame to the SQL table: {e}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
